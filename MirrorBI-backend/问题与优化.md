# 1、AI调用限流

[可以了，基于Redis和Lua实现分布式令牌桶限流 - 知乎](https://zhuanlan.zhihu.com/p/348030329)

为了**防止有用户恶意刷取AI调用，或者用户过多太多的请求导致服务器处理不了崩塌**，可以采用限流的手段进行优化。

> **限流解决了什么问题？**
>
> 保证了服务的**高可用性**，通过**牺牲一定的流量**，来提升系统的稳定性，防止大量流量服务器难以承受而崩溃。

> **限流带来了什么问题？**
>
> - 在服务层面，相当于多添加了一层中间件，引入了额外的开销，**增加了一次I/O环节，分布式限流还要走网络协议**，增加了响应延迟。
> - 引入了限流组件，添加了系统的复杂度，增加维护开销。
> - 限流组件拥有**流控权**，若限流组件崩溃，那么可能会引发**雪崩效应**，使用了该组件的**大部分请求都会失败。**

常见的限流方法有：

- **固定窗口计数**
  - 原理：将时间按照固定的时间间隔分片，对于每个用户，只允许在每一段时间内请求N次，当请求到达N次后就拒绝请求，直到下一个时间片。
  - 实现：**在内存**中维护一个Map，key为用户标识+窗口的起始时间，value为请求计数。或者使用Redis的`INCR`+`EXPIRE`
  - 优点：简单、高效。
  - 缺点：瞬时峰值可能很高，例如1min为一个时间片，用户在59s和1min01秒分别请求了N次，瞬时峰值来到2N。
- **滑动窗口计数**
  - 原理：为每一个请求记录时间戳，保留当前请求前一段时间（如60s）的所有请求时间戳，检查列表长度是否过长超出限制。
  - 实现：在内存或 **Redis 列表/有序集合**中 `LPUSH` 时间戳，然后 `LTRIM` 或者 `ZREMRANGEBYSCORE`。
  - 优点：精准控制任意连续时间内的请求数，没有边界效应。
  - 缺点：存储和遍历开销大。
- **漏桶算法**
  - 将请求看作水滴，灌入一个桶中。桶以恒定的速率“漏水”，进行对应的业务处理，桶满了则拒绝请求。
  - 实现：**维护一个队列来模拟桶**，每隔一段时间就去处理一个请求。
  - 优点：平滑请求输出，适合流量整形需求。
  - 缺点：**突发流量会有较大的排队延迟，对用户体验不佳**。并且因为需要固定速率处理，处理速率较慢，需要按顺序处理。
- **令牌桶算法（Token Bucket）**
  - 系统中心维护一个桶，**桶按照固定的速率产生令牌**，获取到令牌的请求才允许执行，否则需要等待或者拒绝。令牌桶需要有最大容量。
  - 实现：常见于 Linux 流量控制、Guava `RateLimiter`；分布式可用 Redis `INCR` + `EXPIRE` 结合脚本。
  - 优点：支持突发速率：**允许桶中积累令牌，用完后才会限速**。灵活平衡**“长期速率”与“短期峰值”**。
  - 缺点：实现较为复杂，需要计算令牌累积和消耗时机。时间单位选取需要仔细考虑。

# 2、优化Excel数据内嵌在Chart表的实践

在最初的设计方案中，每次导入的Excel数据会被解析成CSV文本数据，然后放置在`Chart`表中的`ChartData`字段。这会导致有以下的问题：

- 若Excel数据过大，那么一条记录就会占据大量的空间，降低查找效率。
- 每条记录都占据大多空间，一张表就会变得很庞大，对未来的增删差改都会带来很大的影响，造成系统的性能下降。

目前的设计是：

```go
type Chart struct {
	ID         uint64         `gorm:"primaryKey;comment:id" json:"id,string" swaggertype:"string"`
	Name       string         `gorm:"type:varchar(128);comment:图表名称" json:"name"`
	Goal       string         `gorm:"type:text;comment:分析目标" json:"goal"`
	ChartData  string         `gorm:"type:text;comment:图表数据" json:"chartData"`
	ChartType  string         `gorm:"type:varchar(128);comment:图表类型" json:"chartType"`
	GenChart   string         `gorm:"type:text;comment:AI生成的图表数据" json:"genChart"`
	GenResult  string         `gorm:"type:text;comment:AI生成的分析结论" json:"genResult"`
	UserID     uint64         `gorm:"comment:创建用户 id" json:"userId,string" swaggertype:"string"`
	CreateTime time.Time      `gorm:"autoCreateTime;comment:创建时间" json:"createTime"`
	UpdateTime time.Time      `gorm:"autoUpdateTime;comment:更新时间" json:"updateTime"`
	IsDelete   gorm.DeletedAt `gorm:"comment:是否删除" swaggerignore:"true" json:"isDelete"`
}
```

## 优化方案1、分表设计，将每个ChartData都分表为chart_{id}

这样是比较容易想出来的，但是带来的缺点也是明显的。**这样子会带来大量的DDL（Data Definition Language）管理和迁移的复杂度，每个图表都需要为之生成一个单独的表，不利于统一的查询和维护。**

## 优化方案2、使用**EAV（Entity-Attribute Value）通用表**

把所有的图表的单元格都放置到一张通用的表中，用`chart_id`来连接原始的表，表的结构抽象成如下格式：

```go
// ChartCell 对应 chart_data_cell 表
type ChartCell struct {
    ID        uint64 `gorm:"primaryKey"`
    ChartID   uint64 `gorm:"index;not null;comment:所属 Chart ID"`
    RowIndex  int    `gorm:"not null;comment:第几行，从0开始"`
    ColName   string `gorm:"type:varchar(128);not null;comment:列名，如 日期/测试/人数"`
    CellValue string `gorm:"type:text;comment:单元格内容"`
    // CreatedAt/UpdatedAt 可选
}
```

记录了行数、列名和列值。假如对于一个CSV例值：

```
日期,测试,人数
5.10号,,10
5.11号,123,20
5.12号,,30
```

那么它的存储结构为：

| chart_id | row_index | col_name | cell_value |
| -------- | --------- | -------- | ---------- |
| 1        | 0         | 日期     | 5.10号     |
| 1        | 0         | 测试     |            |
| 1        | 0         | 人数     | 10         |
| 1        | 1         | 日期     | 5.11号     |
| 1        | 1         | 测试     | 123        |
| 1        | 1         | 人数     | 20         |
| 1        | 2         | 日期     | 5.12号     |
| 1        | 2         | 测试     |            |
| 1        | 2         | 人数     | 30         |

优点：**较易于实现，可以实现行级的数据修改**。

缺点：每一行都需要一条单独的记录，表数据庞大的时候，**增大了内存的开销**。**想要重建成宽表，可能需要多次的JOIN操作，或者SELF-JOIN，I/O开销会很庞大。**可读性差，只能看见零散的格子。

## 落地方案、存储JSON字段

可以单独的提取一张表出来，然后存储的是CSV转化为JSON格式的数据。

```go
import "gorm.io/datatypes"

type ChartDataJSON struct {
    ChartID uint64         `gorm:"primaryKey;comment:图表ID"`
    Data    datatypes.JSON `gorm:"type:json;comment:二维表格数据"`  
}
```

优点：**最容易实现，每条记录都很聚集，查询效率高，直观可读。**查询也天然支持MySQL的JSON函数**做筛选或索引**。

缺点：**不适合做复杂的SQL查询。**

综合分析，当前网站的流量肯定不会很大，并且需要快速推进网站的建设，那么选择存储JSON字段的实现方式是合适的，高效的，收益大的。注意，不管使用哪种方案，**都需要引入事务来确保操作的原子性**。

# 3、开发完限流环节后，系统目前存在的体验问题

目前的AI分析执行流程为，当用户提交了分析需求后，需要等待服务器执行服务，阻塞地等待响应。如果离开页面，虽然结果不会丢失，但是会导致缺少响应的通知、让用户增加了步骤。并且，如果有**大量的用户的请求被阻塞在服务器等待执行**，也会导致系统承受不住压力而崩塌。

为了优化用户的体验，需要开发**异步处理任务**，让用户提交任务后无需进行等待，可以立刻地执行下一个分析任务，当任务执行完毕后，用户可以收到通知。

那么想要实现这一点，**需要解决的技术难点在？**

- 如何实现异步化？可以采用协程。
- 任务的分配如何处理？添加到任务队列中，让协程去处理。
- 如何防止多协程拿到同一个任务？对任务队列采用锁。
- 如何控制协程的数量？可以引入协程池。

对于当前的系统，可以采用以下的流程：

1、用户需要进行一次分析，提交了分析请求，分析到达系统中先保存到数据库里，增加一个处理标识。

2、数据库保存成功后，尝试提交这个新任务：

- 任务提交成功：
  - 若存在空闲的协程，那么让协程直接去处理这个任务。
  - 若不存在空闲的协程，那么让任务存放在消息队列中。
- 任务提交失败，例如不存在空闲协程，并且消息队列任务数量已满：
  - **直接拒绝请求**，不再执行。（数据库存放的数据应该被删除）
  - 后台协程检查提交失败的任务，定期将任务取出处理。

3、任务被完成后，更新任务的处理标识，并且通知用户任务已经完成。（带来的问题：多了一次数据库更新）

4、用户可以查询任务的状态。



为了控制协程池的数量，于是决定引入**ants协程池**。

> 那么，ants为我们**解决了什么问题？**
>
> - **可控的并发边界**：可以控制同时并发进行的任务数量，**防止任务过载压垮CPU/内存**。
> - **任务排队**：没有空闲的worker的时候，可以让任务阻塞，等待有空闲的worker去执行。
> - **任务过载控制**：当超过了设置的队列长度后，多出的任务可以**直接返回失败**，进行对任务的标记。

> ants又**带来了什么问题？**
>
> - **系统的维护复杂度上升**
> - **需要注意参数的控制**，例如资源回收，ants在空闲时会回收goroutine，要配置好最大空闲间隔
> - **依赖风险**

参数设置：

- **WithPreAlloc**：设置为4，提前创建好worker进行预热，当首批请求到来无需延迟。
- **WithPanicHandler**：记录panic异常，进行日志打印，可以随时追溯。
- **WithNonblocking**：设置为true，当任务过多，超出20个，就直接拒绝请求，返回错误。否则，会存在大量的协程占用空间，堆积会使得内存爆炸。
- **Size**：设置为4，最大支持4个AI任务并发。
- **WithMaxBlockingTasks**：设置为20，支持20个AI任务阻塞等待执行。

```go
//获取协程池
	aiPool := GetAiGenPool()
	//异步执行
	go func() {
		var err error
		taskErr := aiPool.Submit(func() {
			//修改chart状态为执行中
			chart.Status = consts.ChartStatusRunning
			chart.ExecMessage = "正在执行"
			updateMap := map[string]interface{}{
				"status":       chart.Status,
				"exec_message": chart.ExecMessage,
			}
			err = s.ChartRepo.UpdateChartByMap(nil, chart.ID, updateMap)
			if err != nil {
				//更新失败，返回错误
				return
			}
			//开始处理任务
			//构造AI调用请求参数
			userRequirement := fmt.Sprintf("分析需求:%s", goal)
			if chartType != "" {
				userRequirement += fmt.Sprintf(",图表类型:%s", chartType)
			}
			//调用API
			res, err := siliconflow.NewLLMChatReqeustNoContext(userRequirement, data)
			if err != nil {
				return
			}
			//提取res中的数据
			genChart, genResult, err := s.GetGenResultAndChart(res.Choices[0].Message.Content)
			if err != nil {
				return
			}
			//保存状态
			chart.GenChart = genChart
			chart.GenResult = genResult
			updateMap = map[string]interface{}{
				"status":       consts.ChartStatusSucceed,
				"exec_message": "执行成功",
				"gen_chart":    chart.GenChart,
				"gen_result":   chart.GenResult,
			}
			//存储数据库
			err = s.ChartRepo.UpdateChartByMap(nil, chart.ID, updateMap)
			if err != nil {
				//更新失败，返回错误
				return
			}
		})
		//进行错误处理
		if taskErr != nil {
			//任务提交失败了，进行数据库的更新
			updateMap := map[string]interface{}{
				"status":       consts.ChartStatusFailed,
				"exec_message": "任务提交失败",
			}
			ERR := s.ChartRepo.UpdateChartByMap(nil, chart.ID, updateMap)
			if ERR != nil {
				//进行日志打印
				log.Println("更新任务失败记录失败", ERR)
				return
			}
		}
		if err != nil{
			//AI任务内部执行出错，记录出错信息
			updateMap := map[string]interface{}{
				"status":       consts.ChartStatusFailed,
				"exec_message": err.Error(),
			}
			ERR := s.ChartRepo.UpdateChartByMap(nil, chart.ID, updateMap)
			if ERR != nil {
				//进行日志打印
				log.Println("更新任务失败记录失败", ERR)
				return
			}
		}
	}()
	//提前返回任务ID
	return chart.ID, nil
```

引入了ants后，可以异步执行AI任务，提前返回数据。