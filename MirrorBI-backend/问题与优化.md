# 1、AI调用限流

为了防止有用户恶意刷取AI调用，或者用户过多太多的请求导致服务器处理不了崩塌，可以采用限流的手段进行优化。常见的限流方法有：

- **固定窗口计数**
  - 原理：将时间按照固定的时间间隔分片，对于每个用户，只允许在每一段时间内请求N次，当请求到达N次后就拒绝请求，直到下一个时间片。
  - 实现：**在内存**中维护一个Map，key为用户标识+窗口的起始时间，value为请求计数。或者使用Redis的`INCR`+`EXPIRE`
  - 优点：简单、高效。
  - 缺点：瞬时峰值可能很高，例如1min为一个时间片，用户在59s和1min01秒分别请求了N次，瞬时峰值来到2N。
- **滑动窗口计数**
  - 原理：为每一个请求记录时间戳，保留当前请求前一段时间（如60s）的所有请求时间戳，检查列表长度是否过长超出限制。
  - 实现：在内存或 **Redis 列表/有序集合**中 `LPUSH` 时间戳，然后 `LTRIM` 或者 `ZREMRANGEBYSCORE`。
  - 优点：精准控制任意连续时间内的请求数，没有边界效应。
  - 缺点：存储和遍历开销大。
- **漏桶算法**
  - 将请求看作水滴，灌入一个桶中。桶以恒定的速率“漏水”，进行对应的业务处理，桶满了则拒绝请求。
  - 实现：**维护一个队列来模拟桶**，每隔一段时间就去处理一个请求。
  - 优点：平滑请求输出，适合流量整形需求。
  - 缺点：**突发流量会有较大的排队延迟，对用户体验不佳**。并且因为需要固定速率处理，处理速率较慢，需要按顺序处理。
- **令牌桶算法（Token Bucket）**
  - 系统中心维护一个桶，**桶按照固定的速率产生令牌**，获取到令牌的请求才允许执行，否则需要等待或者拒绝。令牌桶需要有最大容量。
  - 实现：常见于 Linux 流量控制、Guava `RateLimiter`；分布式可用 Redis `INCR` + `EXPIRE` 结合脚本。
  - 优点：支持突发速率：**允许桶中积累令牌，用完后才会限速**。灵活平衡**“长期速率”与“短期峰值”**。
  - 缺点：实现较为复杂，需要计算令牌累积和消耗时机。时间单位选取需要仔细考虑。

# 2、优化Excel数据内嵌在Chart表的实践

在最初的设计方案中，每次导入的Excel数据会被解析成CSV文本数据，然后放置在`Chart`表中的`ChartData`字段。这会导致有以下的问题：

- 若Excel数据过大，那么一条记录就会占据大量的空间，降低查找效率。
- 每条记录都占据大多空间，一张表就会变得很庞大，对未来的增删差改都会带来很大的影响，造成系统的性能下降。

目前的设计是：

```go
type Chart struct {
	ID         uint64         `gorm:"primaryKey;comment:id" json:"id,string" swaggertype:"string"`
	Name       string         `gorm:"type:varchar(128);comment:图表名称" json:"name"`
	Goal       string         `gorm:"type:text;comment:分析目标" json:"goal"`
	ChartData  string         `gorm:"type:text;comment:图表数据" json:"chartData"`
	ChartType  string         `gorm:"type:varchar(128);comment:图表类型" json:"chartType"`
	GenChart   string         `gorm:"type:text;comment:AI生成的图表数据" json:"genChart"`
	GenResult  string         `gorm:"type:text;comment:AI生成的分析结论" json:"genResult"`
	UserID     uint64         `gorm:"comment:创建用户 id" json:"userId,string" swaggertype:"string"`
	CreateTime time.Time      `gorm:"autoCreateTime;comment:创建时间" json:"createTime"`
	UpdateTime time.Time      `gorm:"autoUpdateTime;comment:更新时间" json:"updateTime"`
	IsDelete   gorm.DeletedAt `gorm:"comment:是否删除" swaggerignore:"true" json:"isDelete"`
}
```

## 优化方案1、分表设计，将每个ChartData都分表为chart_{id}

这样是比较容易想出来的，但是带来的缺点也是明显的。**这样子会带来大量的DDL（Data Definition Language）管理和迁移的复杂度，每个图表都需要为之生成一个单独的表，不利于统一的查询和维护。**

## 优化方案2、使用**EAV（Entity-Attribute Value）通用表**

把所有的图表的单元格都放置到一张通用的表中，用`chart_id`来连接原始的表，表的结构抽象成如下格式：

```go
// ChartCell 对应 chart_data_cell 表
type ChartCell struct {
    ID        uint64 `gorm:"primaryKey"`
    ChartID   uint64 `gorm:"index;not null;comment:所属 Chart ID"`
    RowIndex  int    `gorm:"not null;comment:第几行，从0开始"`
    ColName   string `gorm:"type:varchar(128);not null;comment:列名，如 日期/测试/人数"`
    CellValue string `gorm:"type:text;comment:单元格内容"`
    // CreatedAt/UpdatedAt 可选
}
```

记录了行数、列名和列值。假如对于一个CSV例值：

```
日期,测试,人数
5.10号,,10
5.11号,123,20
5.12号,,30
```

那么它的存储结构为：

| chart_id | row_index | col_name | cell_value |
| -------- | --------- | -------- | ---------- |
| 1        | 0         | 日期     | 5.10号     |
| 1        | 0         | 测试     |            |
| 1        | 0         | 人数     | 10         |
| 1        | 1         | 日期     | 5.11号     |
| 1        | 1         | 测试     | 123        |
| 1        | 1         | 人数     | 20         |
| 1        | 2         | 日期     | 5.12号     |
| 1        | 2         | 测试     |            |
| 1        | 2         | 人数     | 30         |

优点：**较易于实现，可以实现行级的数据修改**。

缺点：每一行都需要一条单独的记录，表数据庞大的时候，**增大了内存的开销**。**想要重建成宽表，可能需要多次的JOIN操作，或者SELF-JOIN，I/O开销会很庞大。**可读性差，只能看见零散的格子。

## 落地方案、存储JSON字段

可以单独的提取一张表出来，然后存储的是CSV转化为JSON格式的数据。

```go
import "gorm.io/datatypes"

type ChartDataJSON struct {
    ChartID uint64         `gorm:"primaryKey;comment:图表ID"`
    Data    datatypes.JSON `gorm:"type:json;comment:二维表格数据"`  
}
```

优点：**最容易实现，每条记录都很聚集，查询效率高，直观可读。**查询也天然支持MySQL的JSON函数**做筛选或索引**。

缺点：**不适合做复杂的SQL查询。**

综合分析，当前网站的流量肯定不会很大，并且需要快速推进网站的建设，那么选择存储JSON字段的实现方式是合适的，高效的，收益大的。注意，不管使用哪种方案，**都需要引入事务来确保操作的原子性**。